{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Understanding word2vec\n",
    "(a) As described in the doc, $\\boldsymbol{y}$ is a one-hot vector with a 1 for the true outside word $o$, that means $y_i$ is 1 if and only if $i == o$. so the proof could be below:\n",
    "\n",
    "$\\begin{aligned} - \\sum_{w\\in Vocab}y_w\\log(\\hat{y}_w) &= - [y_1\\log(\\hat{y}_1) + \\cdots + y_o\\log(\\hat{y}_o) + \\cdots + y_w\\log(\\hat{y}_w)] \\ & = - y_o\\log(\\hat{y}_o) \\ & = -\\log(\\hat{y}_o) \\ & = -\\log \\mathrm{P}(O = o | C = c) \\end{aligned}$\n",
    "\n",
    "(b) we know this deravatives: $$ \\because J = CE(y, \\hat{y}) \\ \\hat{y} = softmax(\\theta)\\ \\therefore \\frac{\\partial J}{\\partial \\theta} = (\\hat{y} - y)^T $$\n",
    "\n",
    "$y$ is a column vector in the above equation. So, we can use chain rules to solve the deravitive:\n",
    "\n",
    "$$\\begin{aligned} \\frac{\\partial J}{\\partial v_c} &= \\frac{\\partial J}{\\partial \\theta} \\frac{\\partial \\theta}{\\partial v_c} \\ &= (\\hat{y} - y) \\frac{\\partial U^Tv_c}{\\partial v_c} \\ &= U^T(\\hat{y} - y)^T \\end{aligned}$$\n",
    "\n",
    "(c) similar to the equation above. $$\\begin{aligned} \\frac{\\partial J}{\\partial v_c} &= \\frac{\\partial J}{\\partial \\theta} \\frac{\\partial \\theta}{\\partial U} \\ &= (\\hat{y} - y) \\frac{\\partial U^Tv_c}{\\partial U} \\ &= v_c(\\hat{y} - y)^T \\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## solution 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the identities tags come from matrix calculus notes.\n",
    "\n",
    "(a) $- \\sum_{w \\in Vocab} y_w \\log(\\hat{y}_w) = -0\\times\\log(\\hat{y_1})-0\\times\\log(\\hat{y_2}) - \\dots -1\\times\\log(\\hat{y_o}) - \\dots - 0\\times \\log(\\hat{y_V})=-\\log(\\hat{y_o})​$\n",
    "\n",
    "(b) Follow the convention of codes, $U \\in \\mathbb{R}^{V\\times N}$, $V$ is the vocabulary size, $N$ is the length of embedding. $y,\\hat{y},v_c,$ are row vectors.\n",
    "\n",
    "From identity $3(7)$ we get: $$ \\frac{\\partial J}{\\partial \\theta} = \\hat{y} - y \\tag1 $$ From identity $3(2)$ we get: $$ \\frac{\\partial \\theta}{\\partial v_c} = U \\tag{2} $$ Combine $(1)$ and $(2)​$ : $$ \\frac{\\partial J}{\\partial v_c} = (\\hat{y} - y)U \\in \\mathbb{R}^{1 \\times N},\\text{same shape with } v_c $$ (c)\n",
    "\n",
    "From identity $3(5)$ we get: $$ \\frac{\\partial J}{\\partial U} = (\\hat{y} - y)v_c \\in \\mathbb{R}^{V \\times N} ,\\text{same shape with } U \\tag{3} $$ then $$ \\frac{\\partial J}{\\partial u_w} = \\text{the } w \\text{ row of } \\frac{\\partial J}{\\partial U} $$ The computing of $J$ involves all the rows of $U$, so it doesn't matter whether $w = o$.\n",
    "\n",
    "(d) $$ \\frac{\\partial \\sigma(x)}{\\partial x} = \\sigma(x)\\sigma(1-\\sigma(x)) $$ (e) $$ s1 = u_o^{\\intercal}v_c, s2 = u_k^{\\intercal}v_c $$\n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial v_c} = (\\sigma(s1)-1))u_o + \\sum_k (1-\\sigma(-s2)) u_k $$\n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial u_o} = (\\sigma(s1)-1))v_c $$\n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial u_k} = (1-\\sigma(-s2)) v_c $$\n",
    "\n",
    "(f)\n",
    "\n",
    "(i) $$ \\frac{\\partial J}{\\partial U} = \\sum_j\\frac{\\partial J(v_c,w_{t+j},U)}{\\partial U} $$ (ii) $$ \\frac{\\partial J}{\\partial v_c} = \\sum_j\\frac{\\partial J(v_c,w_{t+j},U)}{\\partial v_c} $$ (iii)\n",
    "\n",
    "$0$. For the vecotrs that are not the center word, they do not participate in the updata of parameters, they have no influence on the loss. So the answer is $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
